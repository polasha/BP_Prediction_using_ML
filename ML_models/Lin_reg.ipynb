{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>PIR</th>\n",
       "      <th>ptt</th>\n",
       "      <th>hrfinal</th>\n",
       "      <th>ih</th>\n",
       "      <th>il</th>\n",
       "      <th>meu</th>\n",
       "      <th>ppg_21_dt(1)</th>\n",
       "      <th>ppg_21_st(1)+ppg_21_dt(1)</th>\n",
       "      <th>ppg_21_dt(1)/ppg_21_st(1)</th>\n",
       "      <th>...</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>678.68</td>\n",
       "      <td>1.5011</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>122.53</td>\n",
       "      <td>2.8804</td>\n",
       "      <td>1.9189</td>\n",
       "      <td>1.0383</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.8571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.88880</td>\n",
       "      <td>-1.1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>646.98</td>\n",
       "      <td>1.4990</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>116.74</td>\n",
       "      <td>2.8328</td>\n",
       "      <td>1.8899</td>\n",
       "      <td>1.0559</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.176</td>\n",
       "      <td>1.7500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.89156</td>\n",
       "      <td>-1.1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>673.66</td>\n",
       "      <td>1.4339</td>\n",
       "      <td>0.7296</td>\n",
       "      <td>113.46</td>\n",
       "      <td>2.8620</td>\n",
       "      <td>1.9959</td>\n",
       "      <td>1.0557</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.112</td>\n",
       "      <td>1.8000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.88720</td>\n",
       "      <td>-1.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>636.64</td>\n",
       "      <td>1.5166</td>\n",
       "      <td>1.1344</td>\n",
       "      <td>116.74</td>\n",
       "      <td>2.9345</td>\n",
       "      <td>1.9349</td>\n",
       "      <td>1.1431</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.152</td>\n",
       "      <td>1.7143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.88711</td>\n",
       "      <td>-1.1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>957.62</td>\n",
       "      <td>1.0543</td>\n",
       "      <td>2.0768</td>\n",
       "      <td>129.93</td>\n",
       "      <td>2.8711</td>\n",
       "      <td>2.7232</td>\n",
       "      <td>1.1138</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.33600</td>\n",
       "      <td>-0.6640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha     PIR     ptt  hrfinal      ih      il     meu  ppg_21_dt(1)  \\\n",
       "0  678.68  1.5011  0.9952   122.53  2.8804  1.9189  1.0383         0.104   \n",
       "1  646.98  1.4990  0.8432   116.74  2.8328  1.8899  1.0559         0.112   \n",
       "2  673.66  1.4339  0.7296   113.46  2.8620  1.9959  1.0557         0.072   \n",
       "3  636.64  1.5166  1.1344   116.74  2.9345  1.9349  1.1431         0.096   \n",
       "4  957.62  1.0543  2.0768   129.93  2.8711  2.7232  1.1138         0.000   \n",
       "\n",
       "   ppg_21_st(1)+ppg_21_dt(1)  ppg_21_dt(1)/ppg_21_st(1)  ...      t    u    v  \\\n",
       "0                      0.160                     1.8571  ...  0.016  0.0  0.0   \n",
       "1                      0.176                     1.7500  ...  0.032  0.0  0.0   \n",
       "2                      0.112                     1.8000  ...  0.040  0.0  0.0   \n",
       "3                      0.152                     1.7143  ...  0.016  0.0  0.0   \n",
       "4                     -0.320                    -0.0000  ... -0.320 -0.0  0.0   \n",
       "\n",
       "       w    x    y      1    2        3       4  \n",
       "0  0.016  0.0  0.0  0.016  0.0 -0.88880 -1.1112  \n",
       "1  0.032  0.0  0.0  0.032  0.0 -0.89156 -1.1084  \n",
       "2  0.040  0.0  0.0  0.040  0.0 -0.88720 -1.1128  \n",
       "3  0.016  0.0  0.0  0.016  0.0 -0.88711 -1.1129  \n",
       "4 -0.320 -0.0  0.0 -0.320 -0.0 -1.33600 -0.6640  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv ('C:/Users/Omistaja/Desktop/Bpmeasurement/Cuff_less_BP_Prediction/SevendataNanM.csv', names = ['alpha','PIR', 'ptt', 'bpmax' ,'bpmin', 'hrfinal', 'ih', 'il', 'meu', 'ppg_21_dt(1)', 'ppg_21_st(1)+ppg_21_dt(1)','ppg_21_dt(1)/ppg_21_st(1)','m','n','o','p','q','r','s','t','u','v','w','x','y','1','2','3','4'])\n",
    "df_f = pd.read_csv ('C:/Users/Omistaja/Desktop/Bpmeasurement/Cuff_less_BP_Prediction/SevendataNanM.csv')\n",
    "#ppg_21_dt(1) ppg_21_st(1)+ppg_21_dt(1) ppg_21_dt(1)/ppg_21_st(1) ppg_21_dt(2) ppg_21_st(2)+ppg_21_dt(2) ppg_21_dt(2)/ppg_21_st(2) ppg_21_dt(3) ppg_21_st(3)+ppg_21_dt(3) ppg_21_dt(3)/ppg_21_st(3) ppg_21_dt(4) ppg_21_st(4)+ppg_21_dt(4) ppg_21_dt(4)/ppg_21_st(4) ppg_21_dt(5) ppg_21_st(5)+ppg_21_dt(5) ppg_21_dt(5)/ppg_21_st(5) ppg_21_dt(6) ppg_21_st(6)+ppg_21_dt(6) ppg_21_dt(6)/ppg_21_st(6) sys_time dias_time\n",
    "sbp = list()\n",
    "dbp = list()\n",
    "real_BP = list()\n",
    "X = df[['alpha','PIR',  'ptt',  'hrfinal', 'ih', 'il', 'meu', 'ppg_21_dt(1)', 'ppg_21_st(1)+ppg_21_dt(1)','ppg_21_dt(1)/ppg_21_st(1)','m','n','o','p','q','r','s','t','u','v','w','x','y','1','2','3','4']]\n",
    "X.head(5)\n",
    "#X = [[df_f]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x000001D5126706D8>\n"
     ]
    }
   ],
   "source": [
    "with open('C:/Users/Omistaja/Desktop/Bpmeasurement/Cuff_less_BP_Prediction/SevendataNanM.csv', 'r') as csvfile:\n",
    "\tcsv_reader = csv.reader(csvfile, delimiter = ',')\n",
    "\tprint(csv_reader)\n",
    "\tfor row in csv_reader:\n",
    "\t\t#ptt.append(float(row[2]))\n",
    "\t\tsbp.append(float(row[3]))\n",
    "\t\tdbp.append(float(row[4]))\n",
    "\t\t\n",
    "\n",
    "\treal_BP = list()\n",
    "\tfor i in range(len(sbp)):\n",
    "\t\tBP_actual = (2*dbp[i] + sbp[i])/3\n",
    "\t\treal_BP.append(BP_actual)\n",
    "\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X1= X.replace([np.inf, -np.inf], np.nan)\n",
    "#print(np.isnan(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, real_BP, test_size=0.2, random_state=0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X=StandardScaler()\n",
    "x_train=sc_X.fit_transform(X_train)\n",
    "x_test=sc_X.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train= X_train.replace([np.inf, -np.inf], np.nan)\n",
    "#X_test= X_test.replace([np.inf, -np.inf], np.nan)\n",
    "##y_train= y_train.replace([np.inf, -np.inf], np.nan)\n",
    "#print(np.isnan(y_train))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()\n",
    "regression.fit(x_train, y_train)\n",
    "y_pred = regression.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 15.25840228364925\n",
      "Mean Squared Error: 376.90540144215845\n",
      "Root Mean Squared Error: 19.414051649312114\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics  \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "# # Explained variance score: 1 is perfect prediction\n",
    "#print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error_ridge: 17.08698538948135\n",
      "Mean Squared Error_ridge: 465.36436469297854\n",
      "Root Mean Squared Error_ridge: 21.57230550249506\n"
     ]
    }
   ],
   "source": [
    "#Ridge Regression:\n",
    "y_bmin = df[['bpmin']] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dbp, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "Regressor_ridge = Ridge(normalize=True)\n",
    "\n",
    "Regressor_ridge.fit(X_train,y_train)\n",
    "y_pred_ridge = Regressor_ridge.predict(X_test)\n",
    "\n",
    "print('Mean Absolute Error_ridge:', metrics.mean_absolute_error(y_test, y_pred_ridge))  \n",
    "print('Mean Squared Error_ridge:', metrics.mean_squared_error(y_test, y_pred_ridge))  \n",
    "print('Root Mean Squared Error_ridge:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_ridge)))\n",
    "\n",
    "\n",
    "\n",
    "# # Explained variance score: 1 is perfect prediction\n",
    "#print('Variance score_ridge: %.2f' % r2_score(y_test, y_pred_ridge))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:15:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Mean Absolute Error: 18.493560499999997\n",
      "Mean Squared Error: 601.46809271165\n",
      "Root Mean Squared Error: 24.52484643604624\n"
     ]
    }
   ],
   "source": [
    "#adboost model\n",
    "import xgboost\n",
    "\n",
    "y_bmax = df[['bpmax']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dbp, test_size=0.2, random_state=0) \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X=StandardScaler()\n",
    "x_train=sc_X.fit_transform(X_train)\n",
    "x_test=sc_X.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "regressor_xgboost = XGBClassifier()\n",
    "#regressor = LinearRegression() \n",
    "#print dataset.isnull().any()\n",
    "regressor_xgboost.fit(x_train, y_train)\n",
    "y_pred = regressor_xgboost.predict(x_test)\n",
    "\n",
    "\n",
    "#print('Coefficients: \\n', regressor.coef_)\n",
    "# The mean squared error\n",
    "from sklearn import metrics  \n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "\n",
    "\n",
    "# # Explained variance score: 1 is perfect prediction\n",
    "#print('Variance score: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 14.107844577472221\n",
      "Mean Squared Error: 368.1876198826028\n",
      "Root Mean Squared Error: 19.188215651347125\n",
      "Variance score: 0.33\n"
     ]
    }
   ],
   "source": [
    "#Random forest regression\n",
    "y_bminmax = df[['bpmin', 'bpmax']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dbp, test_size=0.2, random_state=0) \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X=StandardScaler()\n",
    "x_train=sc_X.fit_transform(X_train)\n",
    "x_test=sc_X.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor_random = RandomForestRegressor(n_estimators = 500, random_state = 2)\n",
    "\n",
    "#regressor = LinearRegression() \n",
    "#print dataset.isnull().any()\n",
    "regressor_random.fit(x_train, y_train)\n",
    "y_pred = regressor_random.predict(x_test)\n",
    "\n",
    "\n",
    "#print('Coefficients: \\n', regressor.coef_)\n",
    "# The mean squared error\n",
    "from sklearn import metrics  \n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "\n",
    "\n",
    "# # Explained variance score: 1 is perfect prediction\n",
    "#print('Variance score: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 17.489904221062645\n",
      "Mean Squared Error: 497.25407085020447\n",
      "Root Mean Squared Error: 22.299194399130307\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "X = df[['alpha','PIR', 'ptt']]\n",
    "#X = df[['alpha','PIR', 'ptt',  'hrfinal', 'ih', 'il', 'meu', 'j', 'k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','1','2','3','4']]\n",
    "y = df[['bpmin','bpmax']]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X=StandardScaler()\n",
    "sc_y=StandardScaler()\n",
    "X=sc_X.fit_transform(X)\n",
    "#y=sc_y.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dbp, test_size=0.2, random_state=0) \n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc_X=StandardScaler()\n",
    "# x_train=sc_X.fit_transform(X_train)\n",
    "# x_test=sc_X.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "regressor_svm = SVR(kernel = 'rbf')\n",
    "#regressor = LinearRegression() \n",
    "#print dataset.isnull().any()\n",
    "regressor_svm.fit(X_train, y_train)\n",
    "y_pred = regressor_svm.predict(X_test)\n",
    "\n",
    "\n",
    "#print('Coefficients: \\n', regressor.coef_)\n",
    "# The mean squared error\n",
    "from sklearn import metrics  \n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "\n",
    "\n",
    "# # Explained variance score: 1 is perfect prediction\n",
    "#print('Variance score: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 16.64509759874323\n",
      "Mean Squared Error: 440.2057744561543\n",
      "Root Mean Squared Error: 20.981081346206974\n"
     ]
    }
   ],
   "source": [
    "#Adaboost\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "#X = dataset[[  'ptt','p1','p2','p3','p4','p5','p6','p7','p8','p9']]\n",
    "\n",
    "#y = dataset[['bpmin']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dbp, test_size=0.1, random_state=1) \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X=StandardScaler()\n",
    "x_train=sc_X.fit_transform(X_train)\n",
    "x_test=sc_X.transform(X_test)\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "regr_1 = DecisionTreeRegressor(max_depth=4)\n",
    "\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),\n",
    "                          n_estimators=300, random_state=rng)\n",
    "\n",
    "regr_1.fit(X_train, y_train)\n",
    "regr_2.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = regr_1.predict(X_test)\n",
    "y_pre = regr_2.predict(X_test)\n",
    "\n",
    "#print('Coefficients: \\n', regressor.coef_)\n",
    "# The mean squared error\n",
    "from sklearn import metrics  \n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pre))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pre))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pre)))\n",
    "\n",
    "\n",
    "\n",
    "# # Explained variance score: 1 is perfect prediction\n",
    "#print('Variance score: %.2f' % r2_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2432500e105f57fda4830892c70a890de0b4908c22567f4effe7bd1a6873d39c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
